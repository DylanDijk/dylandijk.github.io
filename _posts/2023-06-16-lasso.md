---
layout: post
title: Lasso
date: 2023-06-16 15:35 +0000
---

# Lasso

**Main references**:
  - [Statistical learning with sparsity](https://hastie.su.domains/StatLearnSparsity_files/SLS_corrected_1.4.16.pdf) - by Hastie, Tibshirani and Wainwright
  - 

## Problem statement

The objective of Lasso is:

$$
\min_{\beta \in \mathbb{R}^p} \|y - X\beta\|_2^2 \\
\text{subject to} \quad \|\beta\|_1 \leq t
$$

The objective function $||y - X\beta||_2^2$ is convex, as the Hessian is $2X^TX$, which is positive semidefinite. Alternatively, it can be seen that $||y - X\beta||_2^2$ is convex, by using that the composition of convex functions is convex. And that Norms are convex functions, $f(x) = x^2$ is convex, and linear functions are convex
The same argument can be used to show that the constraint is convex, and hence the Lasso problem is a convex optimisation problem.

## Lagrangian form

As described in the [duality](https://dylandijk.github.io/posts/duality/) post, we can reformulate a constrained optimisation problem into an unconstrained Lagrange form. And for a convex problem, we have sufficients and necessary KKT conditions for optimality. 






